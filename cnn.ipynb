{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm as tn\n",
    "import tensorflow as tf\n",
    "from timeit import timeit,Timer\n",
    "from GameController import *\n",
    "import itertools\n",
    "import sys\n",
    "import objgraph\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(m_input,size_in,size_out,k_size_w,k_size_h,conv_stride,pool_k_size,pool_stride_size,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        w = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/\"+name+num+\"/w\"+num+\":0\")\n",
    "        b = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/\"+name+num+\"/b\"+num+\":0\")\n",
    "        conv = tf.nn.conv2d(m_input,w,strides=[1,conv_stride,conv_stride,1],padding=\"SAME\")\n",
    "        act = tf.nn.leaky_relu((conv+b),alpha=0.3)\n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return tf.nn.max_pool(act,ksize=[1,pool_k_size,pool_k_size,1],strides=[1,pool_stride_size,pool_stride_size,1],padding='SAME')\n",
    "\n",
    "\n",
    "def fc_layer(m_input,size_in,size_out,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        w = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/\"+name+num+\"/w\"+num+\":0\")\n",
    "        b = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/\"+name+num+\"/b\"+num+\":0\")\n",
    "        z = tf.matmul(m_input,w)\n",
    "        act = tf.nn.leaky_relu(z+b,alpha=0.3,name=(\"act\"+num))\n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return act\n",
    "\n",
    "def conv_weights(size_in,size_out,k_size_w,k_size_h,name,num):\n",
    "    w = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/w\"+num+\"cur:0\")\n",
    "    b = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/b\"+num+\"cur:0\")\n",
    "    with tf.name_scope(name+num):\n",
    "        tf.Variable(w,name=\"w\"+num)\n",
    "        tf.Variable(b,name=\"b\"+num)\n",
    "\n",
    "def fc_weights(size_in,size_out,name,num):\n",
    "    w = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/w\"+num+\"cur:0\")\n",
    "    b = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/b\"+num+\"cur:0\")\n",
    "    with tf.name_scope(name+num):\n",
    "        tf.Variable(w,name=\"w\"+num)\n",
    "        tf.Variable(b,name=\"b\"+num)\n",
    "    \n",
    "def conv_weights_container(size_in, size_out, k_size_w, k_size_h,name,num):\n",
    "    sdev = np.power(2.0/(k_size_w*k_size_h*size_in),0.5)\n",
    "    print(\"sdev\"+name+num+\": \",sdev)\n",
    "    lower,upper = -1,1\n",
    "    mu = 0\n",
    "    wi = tn((lower-mu)/sdev,(upper-mu)/sdev,loc = mu,scale=sdev).rvs(size=[k_size_w,k_size_h,size_in,size_out])\n",
    "    bi = np.full(size_out,.1)\n",
    "    \n",
    "    w1 = tf.Variable(wi,dtype=tf.float16,name=(\"w\"+num+\"cur\"),trainable=False)\n",
    "    b1 = tf.Variable(bi,dtype=tf.float16,name=(\"b\"+num+\"cur\"),trainable=False)\n",
    "    w2 = tf.Variable(wi,dtype=tf.float16,name=(\"w\"+num+\"pre\"),trainable=False)\n",
    "    b2 = tf.Variable(bi,dtype=tf.float16,name=(\"b\"+num+\"pre\"),trainable=False)\n",
    "    \n",
    "        \n",
    "def fc_weights_container(size_in,size_out,name,num):\n",
    "    sdev = np.power(2.0/(size_in*size_out),0.5)\n",
    "    print(\"sdev\"+name+num+\": \",sdev)\n",
    "    lower,upper = -1,1\n",
    "    mu = 0\n",
    "    wi = tn((lower-mu)/sdev,(upper-mu)/sdev,loc = mu,scale=sdev).rvs(size=[size_in,size_out])\n",
    "    bi = np.full(size_out,.1)\n",
    "\n",
    "    w1 = tf.Variable(wi,dtype=tf.float16,name=(\"w\"+num+\"cur\"),trainable=False)\n",
    "    b1 = tf.Variable(bi,dtype=tf.float16,name=(\"b\"+num+\"cur\"),trainable=False)\n",
    "    w2 = tf.Variable(wi,dtype=tf.float16,name=(\"w\"+num+\"pre\"),trainable=False)\n",
    "    b2 = tf.Variable(bi,dtype=tf.float16,name=(\"b\"+num+\"pre\"),trainable=False)\n",
    "    \n",
    "    \n",
    "def get_place_holders():\n",
    "    a = tf.get_default_graph().get_tensor_by_name(\"place_holder/x1:0\")\n",
    "    b = tf.get_default_graph().get_tensor_by_name(\"place_holder/y:0\")\n",
    "    c = tf.get_default_graph().get_tensor_by_name(\"place_holder/x2:0\")\n",
    "    d = tf.get_default_graph().get_tensor_by_name(\"place_holder/next_state:0\")\n",
    "    e = tf.get_default_graph().get_tensor_by_name(\"place_holder/qnext:0\")\n",
    "    return a,b,c,d,e\n",
    "\n",
    "def get_network_WB():\n",
    "    CW1 = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/conv1/w1:0\")\n",
    "    CW2 = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/conv2/w2:0\")\n",
    "    FW1 = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/FC1/w1:0\")\n",
    "    FW2 = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/FC2/w2:0\")\n",
    "\n",
    "    CB1 = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/conv1/b1:0\")\n",
    "    CB2 = tf.get_default_graph().get_tensor_by_name(\"network_conv_weights/conv2/b2:0\")\n",
    "    FB1 = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/FC1/b1:0\")\n",
    "    FB2 = tf.get_default_graph().get_tensor_by_name(\"network_fc_weights/FC2/b2:0\")\n",
    "    \n",
    "    return [CW1,CW2,FW1,FW2],[CB1,CB2,FB1,FB2]\n",
    "\n",
    "def assign_weights_to_network(dim):\n",
    "    weights,biases = get_network_WB()\n",
    "    wcur,bcur,wpre,bpre = get_container_WB()\n",
    "    \n",
    "    if (dim == 0):\n",
    "        wval = wcur\n",
    "        bval = bcur\n",
    "    else:\n",
    "        wval = wpre\n",
    "        bval = bpre\n",
    "        \n",
    "    ops = []\n",
    "    for i in range(0,len(weights)):\n",
    "        ops.append(tf.assign(weights[i],wval[i]))\n",
    "        ops.append(tf.assign(biases[i],bval[i]))\n",
    "    sess.run(ops)\n",
    "    \n",
    "    return\n",
    "\n",
    "def update_container_matricies(sess):\n",
    "    w,b = get_network_WB()\n",
    "    wcur,bcur,wpre,bpre = get_container_WB()\n",
    "    \n",
    "    ops = []\n",
    "    for i in range(0,len(wcur)):\n",
    "        ops.append(tf.assign(wpre[i],wcur[i]))\n",
    "        ops.append(tf.assign(bpre[i],bcur[i]))\n",
    "    sess.run(ops)\n",
    "    \n",
    "    ops = []\n",
    "    for i in range(0,len(wcur)):\n",
    "        ops.append(tf.assign(wcur[i],w[i]))\n",
    "        ops.append(tf.assign(bcur[i],b[i]))\n",
    "    sess.run(ops)\n",
    "    return\n",
    "\n",
    "def test_update_container_matricies(sess):\n",
    "    w,b = get_network_WB()\n",
    "    w1,b1 = get_test_WB()\n",
    "    \n",
    "    ops = []\n",
    "    for i in range(0,len(w1)):\n",
    "        ops.append((w1[i][1]).assign(w1[i][0]))\n",
    "        ops.append((b1[i][1]).assign(b1[i][0]))\n",
    "    sess.run(ops)\n",
    "    \n",
    "    ops = []\n",
    "    for i in range(0,len(w1)):\n",
    "        ops.append(w1[i][0].assign(w[i]))\n",
    "        ops.append(b1[i][0].assign(b[i]))\n",
    "    sess.run(ops)\n",
    "    return\n",
    "    \n",
    "\n",
    "def print_test_FC(sess):\n",
    "    wcur,bcur,wpre,bpre = get_container_WB()\n",
    "    w1,b1 = get_network_WB()\n",
    "    print(\"current: \",sess.run([wcur[2][0][0]]))\n",
    "    print(\"previous: \",sess.run([wpre[2][0][0]]))\n",
    "    print(\"current NN\",sess.run([w1[2][0][0]]))\n",
    "    print(\" \")\n",
    "    \n",
    "def get_container_WB():\n",
    "    CW1cur = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/w1cur:0\")\n",
    "    CW2cur = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/w2cur:0\")\n",
    "    FW1cur = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/w1cur:0\")\n",
    "    FW2cur = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/w2cur:0\")\n",
    "    \n",
    "    CW1pre = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/w1pre:0\")\n",
    "    CW2pre = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/w2pre:0\")\n",
    "    FW1pre = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/w1pre:0\")\n",
    "    FW2pre = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/w2pre:0\")\n",
    "\n",
    "    CB1cur = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/b1cur:0\")\n",
    "    CB2cur = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/b2cur:0\")\n",
    "    FB1cur = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/b1cur:0\")\n",
    "    FB2cur = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/b2cur:0\")\n",
    "    \n",
    "    CB1pre = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/b1pre:0\")\n",
    "    CB2pre = tf.get_default_graph().get_tensor_by_name(\"conv_weights_container/b2pre:0\")\n",
    "    FB1pre = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/b1pre:0\")\n",
    "    FB2pre = tf.get_default_graph().get_tensor_by_name(\"fc_weights_container/b2pre:0\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return [CW1cur,CW2cur,FW1cur,FW2cur],[CB1cur,CB2cur,FB1cur,FB2cur],[CW1pre,CW2pre,FW1pre,FW2pre],[CB1pre,CB2pre,FB1pre,FB2pre]\n",
    "    \n",
    "def trainer(current_state,next_state,reward,gamma):\n",
    "    train = tf.get_default_graph().get_operation_by_name(\"train/trainer\")\n",
    "    x1,y,x2,next_state_bool,Qnext= get_place_holders()\n",
    "    q_compute = tf.get_default_graph().get_tensor_by_name(\"Qnext_val:0\")\n",
    "    action = tf.get_default_graph().get_tensor_by_name(\"action/action:0\")\n",
    "    \n",
    "    #print(\"Before Next State\")\n",
    "    #print_test_FC(sess)\n",
    "    Qnext_val = sess.run([q_compute],{x1: current_state, x2: next_state,next_state_bool: True})\n",
    "    Qnext_val = reward+(gamma*np.max(Qnext_val))\n",
    "    Qnext_val = np.array(Qnext_val).reshape((1,1))\n",
    "    #print(\"After Next State True\")\n",
    "    #print_test_FC(sess)\n",
    "    s = sess.run([train],{x1: current_state,x2: next_state, next_state_bool: False, Qnext: Qnext_val})\n",
    "    #print(\"After Train\")\n",
    "    #print_test_FC(sess)\n",
    "    return\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,batch_size,conv_count,fc_count,conv_feats,fc_feats,conv_k_size,conv_stride):\n",
    "    LOGDIR = r\"C:\\Users\\Vishnu\\Documents\\EngProj\\SSPlayer\\log\"\n",
    "    if (len(conv_feats) != conv_count):\n",
    "        return\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"place_holder\"):\n",
    "        x1 = tf.placeholder(tf.float16,shape=[None,110,84,4],name=\"x1\")\n",
    "        y = tf.placeholder(tf.float16,shape=[None,4],name=\"y\")\n",
    "        x2 = tf.placeholder(tf.float16,shape=[None,110,84,4],name=\"x2\")\n",
    "        next_state = tf.placeholder(tf.bool,name=\"next_state\")\n",
    "        Qnext = tf.placeholder(tf.float16,shape=[None,1],name=\"qnext\")\n",
    "\n",
    "    conv_name=\"conv\"\n",
    "    conv_feats[0] = 4\n",
    "    p = 0\n",
    "    with tf.name_scope(\"conv_weights_container\"):\n",
    "        for i in range(0,conv_count-1):\n",
    "            conv_weights_container(conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_k_size[p],conv_name,str(i+1))\n",
    "            p = p+1\n",
    "    \n",
    "    p = 0\n",
    "    with tf.name_scope(\"network_conv_weights\"):\n",
    "        for i in range(0,conv_count-1):\n",
    "            conv_weights(conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_k_size[p],conv_name,str(i+1))\n",
    "            p = p+1\n",
    "    \n",
    "    p = 0\n",
    "    fcs_name=\"FC\"\n",
    "    fc_feats[0] = conv_feats[len(conv_feats)-1]*4\n",
    "    with tf.name_scope(\"fc_weights_container\"):\n",
    "        for i in range(0,fc_count-1):\n",
    "            fc_weights_container(fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))\n",
    "    \n",
    "    p = 0\n",
    "    with tf.name_scope(\"network_fc_weights\"):\n",
    "        for i in range(0,fc_count-1):\n",
    "            fc_weights(fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))\n",
    "            p = p+1\n",
    "        \n",
    "    \n",
    "    weights,biases = get_network_WB()\n",
    "    wcur,bcur,wpre,bpre = get_container_WB()\n",
    "    \n",
    "    def f_true():\n",
    "        #if next_state = true\n",
    "        #Replace all weights with previous\n",
    "        ops = []\n",
    "        for i in range(0,len(weights)):\n",
    "            ops.append(tf.assign(wcur[i],weights[i]))\n",
    "            ops.append(tf.assign(bcur[i],biases[i]))\n",
    "            ops.append(tf.assign(weights[i],wpre[i]))\n",
    "            ops.append(tf.assign(biases[i],bpre[i]))\n",
    "\n",
    "        return ops\n",
    "        \n",
    "    def f_false():\n",
    "        #if next_state = false\n",
    "        #Replace all weights with current\n",
    "        ops = []\n",
    "        for i in range(0,len(weights)):\n",
    "            ops.append(tf.assign(weights[i],wcur[i]))\n",
    "            ops.append(tf.assign(biases[i],bcur[i]))\n",
    "            ops.append(tf.assign(wpre[i],wcur[i]))\n",
    "            ops.append(tf.assign(bpre[i],bcur[i]))\n",
    "        \n",
    "        return ops\n",
    "\n",
    "    control_ops = tf.cond(next_state,f_true,f_false,name=\"control_op_cond\")\n",
    "    \n",
    "    in_image = tf.cond(next_state,lambda: x2,lambda: x1,name=\"state_condition\")\n",
    "    \n",
    "    with tf.control_dependencies(control_ops):\n",
    "        with tf.name_scope(\"convolution_layers\"):\n",
    "            convs = []\n",
    "            convs.append(in_image)    \n",
    "            p = 0\n",
    "            for i in range(0,conv_count-1):\n",
    "                convs.append(conv_layer(convs[i],conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_k_size[p],conv_stride[p],2,2,conv_name,str(i+1)))\n",
    "    \n",
    "\n",
    "        flatten = tf.reshape(convs[conv_count-1],[-1,fc_feats[0]])\n",
    "    \n",
    "        with tf.name_scope(\"dense_layers\"):\n",
    "            fcs = []\n",
    "            fcs.append(flatten)\n",
    "            for i in range(0,fc_count-1):\n",
    "                fcs.append((fc_layer(fcs[i],fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))))\n",
    "    \n",
    "        output_layer = fcs[len(fcs)-1]\n",
    "            \n",
    "    with tf.name_scope(\"train\"):\n",
    "        loss = tf.reduce_sum(tf.pow(Qnext-output_layer,2))\n",
    "        tf.summary.scalar(\"loss\",loss)\n",
    "        train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,name=\"trainer\")\n",
    "\n",
    "    \n",
    "    Qnext_val = tf.reduce_max(output_layer,name=\"Qnext_val\")\n",
    "    action = tf.argmax(output_layer,axis=1,name=\"action\")\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    return sess,writer,summ,[x1,x2,y,next_state,Qnext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdevconv1:  0.08838834764831845\n",
      "sdevconv2:  0.08838834764831845\n",
      "sdevFC1:  0.011180339887498949\n",
      "sdevFC2:  0.06324555320336758\n"
     ]
    }
   ],
   "source": [
    "conv_k_size = [8,4]\n",
    "conv_stride = [4,2]\n",
    "conv = [0,16,32]\n",
    "fclyr = [0,125,4]\n",
    "conv_count = len(conv)\n",
    "fc_count = len(fclyr)\n",
    "learning_rate = 1e-4\n",
    "batch_size = 10\n",
    "sess,writer,summ,place_holders= create_model(learning_rate,batch_size,conv_count,fc_count,conv,fclyr,conv_k_size,conv_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_action(seq):\n",
    "    action = tf.get_default_graph().get_tensor_by_name(\"action:0\")\n",
    "    x1,y,x2,next_state_bool,Qnext= get_place_holders()\n",
    "    return sess.run([action],{x1: seq,x2: np.random.rand(1,110,84,4),next_state_bool: True})\\\n",
    "\n",
    "\n",
    "def send_action_to_game_controller(game,a,pp):\n",
    "    if (a == 0):\n",
    "        game.move_mouse_up()\n",
    "    elif (a == 1):\n",
    "        game.move_mouse_down()\n",
    "    elif (a == 2):\n",
    "        game.move_mouse_left()\n",
    "    else:\n",
    "        game.move_mouse_right()\n",
    "    \n",
    "    r = game.get_reward()\n",
    "    frames,bval = get_4_frames(game,pp)\n",
    "    return r,frames,bval\n",
    "\n",
    "def random_minibatch_sample(batchsize):\n",
    "    global exp\n",
    "    \n",
    "    line_N = np.random.randint(0,len(exp),size=batchsize)\n",
    "    return np.asarray([exp[i] for i in line_N]).transpose()\n",
    "    #return [row for idx, row in enumerate(reader) if idx in line_N]\n",
    "    \n",
    "def get_seq_y(seq,gamma):\n",
    "    q_compute = tf.get_default_graph().get_tensor_by_name(\"Qnext_val:0\")\n",
    "    x1,y,x2,next_state_bool,Qnext = get_place_holders()\n",
    "    \n",
    "    \n",
    "    imgs_2 = seq[3,:]\n",
    "    imgs_2 = ((1.0/256)*imgs_2).astype(np.float16)\n",
    "    imgs_1 = seq[0,:]\n",
    "    imgs_1 = ((1.0/256)*imgs_2).astype(np.float16)\n",
    "    \n",
    "    dummy = np.random.rand(1,110,84,4)\n",
    "    q_vals = [np.squeeze(sess.run([q_compute],{x1: dummy,x2: i, next_state_bool: True})) for i in imgs_2]\n",
    "    r_vals = seq[2,:].tolist()\n",
    "    \n",
    "    q_vals = np.array(q_vals)\n",
    "    r_vals = np.array(r_vals)\n",
    "    #print(\"q_vals: \", q_vals)\n",
    "    y = (r_vals+(gamma*q_vals)).reshape(len(r_vals),1)\n",
    "    return y,np.squeeze(np.array(imgs_1))\n",
    "    \n",
    "def store_exp(seq):\n",
    "    global exp\n",
    "    img_1 = seq[0]\n",
    "    img_2 = seq[3]\n",
    "    img_1 = (256*img_1).round().astype(np.uint8)\n",
    "    img_2 = (256*img_2).round().astype(np.uint8)\n",
    "    seq[0] = img_1.tolist()\n",
    "    seq[3] = img_2.tolist()\n",
    "    exp.append(seq)\n",
    "    return\n",
    "\n",
    "def train_network(batch_size,gamma):\n",
    "    #Required tensorflow variables and operations\n",
    "    global writer,summ,it\n",
    "    x1,y,x2,next_state_bool,Qnext = get_place_holders()\n",
    "    train = tf.get_default_graph().get_operation_by_name(\"train/trainer\")\n",
    "    seq = random_minibatch_sample(batch_size)\n",
    "    #Getting y values and the corresponding training images\n",
    "    y_vals,images = get_seq_y(seq,gamma)\n",
    "    images = np.squeeze(images)\n",
    "    dummy = np.random.rand(1,110,84,4)\n",
    "    t,s = sess.run([train,summ],{x1: images,x2: dummy,Qnext: y_vals,next_state_bool:False})\n",
    "    writer.add_summary(s,it)\n",
    "    it = it+1\n",
    "    return\n",
    "\n",
    "def get_4_frames(game,pp):\n",
    "    imgs = [take_shot(pp) for i in range(0,4)]\n",
    "    bval = [game.get_screen_number(i) for i in imgs]\n",
    "    imgs = [img_standardize(i) for i in imgs]\n",
    "    imgs = np.array(imgs)\n",
    "    imgs = img_standardize(imgs)\n",
    "    imgs = np.rollaxis(imgs,0,3)\n",
    "    if max(bval) == 3:\n",
    "        return imgs,True\n",
    "    else:\n",
    "        return imgs,False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_sequence(size):\n",
    "    seq = []\n",
    "    for i in range(0,size):\n",
    "        vec = []\n",
    "        vec.append(np.random.rand(1,110,84,4).astype(np.int8))\n",
    "        vec.append(np.random.randint(0,4))\n",
    "        vec.append(np.random.random_sample(1).astype(np.int8))\n",
    "        vec.append(np.random.rand(1,110,84,4).astype(np.int8))\n",
    "        seq.append(vec)\n",
    "    return np.asarray(seq)\n",
    "\n",
    "def run(game,greed,M,pp,batch_size,gamma):\n",
    "    global exp\n",
    "    for i in range(0,M):  #New play\n",
    "        if (i > 10):\n",
    "            greed = .3\n",
    "        wait_for(1)\n",
    "        game.click_to_play()\n",
    "        seq = []\n",
    "        p = 0\n",
    "        while game.get_screen_number(take_shot(pp)) is not 3: #for j in range(0,T): #While play active\n",
    "            frames,test = get_4_frames(game,pp)\n",
    "            if (test):\n",
    "                break\n",
    "            seq.append(frames)\n",
    "            if np.random.random_sample(1) <= greed:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = infer_action([seq[0]])\n",
    "            r,frames,test = send_action_to_game_controller(game,a,pp)\n",
    "            if (test):\n",
    "                break\n",
    "            seq.append(a)\n",
    "            seq.append(r)\n",
    "            seq.append(frames)\n",
    "            store_exp(seq)\n",
    "            seq = []\n",
    "            #if (len(exp) > 10):\n",
    "            #    train_network(batch_size,gamma)\n",
    "        game.release_click()\n",
    "        wait_for(.3)\n",
    "        game.click_replay()\n",
    "        print(\"Iteration: \",i)\n",
    "        print(\"size: \",len(exp))\n",
    "        print(\"size bytes: \",sys.getsizeof(exp))\n",
    "        print(\"mem: \",process.memory_info().rss)\n",
    "        \n",
    "def play_game(game,M,pp):\n",
    "    for i in range(0,M):\n",
    "        wait_for(1)\n",
    "        game.click_to_play()\n",
    "        while game.get_screen_number(take_shot(pp)) is not 3:\n",
    "            frames,test = get_4_frames(game,pp)\n",
    "            if (test):\n",
    "                break\n",
    "            a = infer_action([frames])\n",
    "            r,frames,test = send_action_to_game_controller(game,a,pp)\n",
    "            if (test):\n",
    "                break\n",
    "        game.release_click()\n",
    "        wait_for(.3)\n",
    "        game.click_replay()\n",
    "        print(\"Play Iteration: \",i)\n",
    "        print(\"List Size\", len(exp))\n",
    "        print(\"size: \",sys.getsizeof(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishnu\\envs\\rl\\lib\\site-packages\\pywinauto\\application.py:1032: UserWarning: 32-bit application should be automated using 32-bit Python (you use 64-bit Python)\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "size:  30\n",
      "size bytes:  344\n",
      "mem:  233054208\n",
      "Iteration:  1\n",
      "size:  56\n",
      "size bytes:  528\n",
      "mem:  285249536\n",
      "Iteration:  2\n",
      "size:  89\n",
      "size bytes:  912\n",
      "mem:  350556160\n",
      "Iteration:  3\n",
      "size:  104\n",
      "size bytes:  912\n",
      "mem:  380964864\n",
      "Iteration:  4\n",
      "size:  125\n",
      "size bytes:  1072\n",
      "mem:  422871040\n",
      "Iteration:  5\n",
      "size:  135\n",
      "size bytes:  1248\n",
      "mem:  442507264\n",
      "Iteration:  6\n",
      "size:  168\n",
      "size bytes:  1448\n",
      "mem:  508932096\n",
      "Iteration:  7\n",
      "size:  184\n",
      "size bytes:  1672\n",
      "mem:  537542656\n",
      "Iteration:  8\n",
      "size:  198\n",
      "size bytes:  1672\n",
      "mem:  568332288\n",
      "Iteration:  9\n",
      "size:  214\n",
      "size bytes:  1928\n",
      "mem:  600076288\n",
      "Iteration:  10\n",
      "size:  242\n",
      "size bytes:  2216\n",
      "mem:  655720448\n",
      "Iteration:  11\n",
      "size:  252\n",
      "size bytes:  2216\n",
      "mem:  675352576\n",
      "Iteration:  12\n",
      "size:  269\n",
      "size bytes:  2216\n",
      "mem:  709316608\n",
      "Iteration:  13\n",
      "size:  295\n",
      "size bytes:  2536\n",
      "mem:  761425920\n",
      "Iteration:  14\n",
      "size:  301\n",
      "size bytes:  2536\n",
      "mem:  773124096\n",
      "2536\n"
     ]
    }
   ],
   "source": [
    "r = 1\n",
    "it = 0\n",
    "exp = []\n",
    "app_dir = r\"C:\\Users\\Vishnu\\Documents\\EngProj\\SSPlayer\\Release.win32\\ShapeScape.exe\"\n",
    "if r:\n",
    "    if __name__ == \"__main__\":\n",
    "        game = SSPlayer(app_dir,1)\n",
    "        #Image.fromarray(game.crop_image_for_test(take_shot(game.processing_crop))).save('mainscene.png')\n",
    "        wait_for(1)\n",
    "        game.click_play()\n",
    "        run(game,.7,15,game.processing_crop,2,.9)\n",
    "        print(sys.getsizeof(exp))\n",
    "        #del exp[:]\n",
    "        #play_game(game,15,game.processing_crop)\n",
    "        #sess.close()\n",
    "        #t_img = multiprocessing.Queue()\n",
    "        #ev = multiprocessing.Event()\n",
    "        #pp = game.processing_crop\n",
    "        #p = multiprocessing.Process(target=multi_add_training_images,args=[t_img,ev,pp])\n",
    "\n",
    "        #print(Timer(lambda: Run(game,p,ev,t_img)).timeit(number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 4)\n"
     ]
    }
   ],
   "source": [
    "def save_imgs(exp):\n",
    "    img_1 = []\n",
    "    img_2 = []\n",
    "    for i in exp:\n",
    "        img_1.append(np.array(i[0]).squeeze())\n",
    "        img_2.append(np.array(i[3]).squeeze())\n",
    "    \n",
    "    print(np.shape(img_1))\n",
    "    print(np.shape(img_2))\n",
    "    \n",
    "    imgs= []\n",
    "    for i in img_1:\n",
    "        imgs.append(i[:,:,0])\n",
    "        imgs.append(i[:,:,1])\n",
    "        imgs.append(i[:,:,2])\n",
    "        imgs.append(i[:,:,3])\n",
    "        \n",
    "    \n",
    "    for i in img_2:\n",
    "        imgs.append(i[:,:,0])\n",
    "        imgs.append(i[:,:,1])\n",
    "        imgs.append(i[:,:,2])\n",
    "        imgs.append(i[:,:,3])\n",
    "        \n",
    "    \n",
    "    print(np.shape(imgs))\n",
    "    print(sys.getsizeof(imgs)/1000)\n",
    "    for i in range(0,len(imgs)):\n",
    "        Image.fromarray(imgs[i]).save(r\"test\\frame\"+str(i)+\".png\")\n",
    "print(np.shape(exp))\n",
    "#save_imgs(exp)\n",
    "game.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test():\n",
    "    x1,y,x2,next_state_bool,Qnext = get_place_holders()\n",
    "    train = tf.get_default_graph().get_operation_by_name(\"train/trainer\")\n",
    "    dummy = np.random.rand(25,110,84,4)\n",
    "    y_vals = np.random.rand(25,1)\n",
    "    sess.run([train],{x1: dummy,x2: dummy,Qnext: y_vals,next_state_bool:False})\n",
    "    return\n",
    "\n",
    "if False:\n",
    "    print(Timer(lambda: test()).timeit(number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del exp[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psutil.Process(pid=7784, name='python.exe', started='19:59:13')\n"
     ]
    }
   ],
   "source": [
    "print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
