{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(m_input,size_in,size_out,k_size_w,k_size_h,conv_stride,pool_k_size,pool_stride_size,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        sdev = np.power(2.0/(k_size_w*k_size_h*size_in),0.5)\n",
    "        print(\"sdev\"+name+num+\": \",sdev)\n",
    "        w = tf.Variable(tf.truncated_normal([k_size_w,k_size_h,size_in,size_out],stddev = sdev),name=(\"w\"+num))\n",
    "        b = tf.Variable(tf.constant(.1,shape=[size_out]),name=(\"b\"+num))\n",
    "\n",
    "        conv = tf.nn.conv2d(m_input,w,strides=[1,conv_stride,conv_stride,1],padding=\"SAME\")\n",
    "        act = tf.nn.leaky_relu((conv+b),alpha=0.3)\n",
    "        \n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return tf.nn.max_pool(act,ksize=[1,pool_k_size,pool_k_size,1],strides=[1,pool_stride_size,pool_stride_size,1],padding='SAME')\n",
    "\n",
    "\n",
    "def fc_layer(m_input,size_in,size_out,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        sdev = np.power(2.0/(size_in*size_out),0.5)\n",
    "        print(\"sdev\"+name+num+\": \",sdev)\n",
    "        w = tf.Variable(tf.truncated_normal([size_in,size_out],stddev = sdev),name=(\"w\"+num))\n",
    "        b = tf.Variable(tf.constant(0.1,shape=[size_out]),name=(\"b\"+num))\n",
    "        z = tf.matmul(m_input,w)\n",
    "        act = tf.nn.leaky_relu(z+b,alpha=0.3)\n",
    "\n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return act\n",
    "    \n",
    "def construct_weight_matricies():\n",
    "    CW1 = tf.get_default_graph().get_tensor_by_name(\"conv1/w1:0\")\n",
    "    CW2 = tf.get_default_graph().get_tensor_by_name(\"conv2/w2:0\")\n",
    "    \n",
    "    FW1 = tf.get_default_graph().get_tensor_by_name(\"FC1/w1:0\")\n",
    "    FW2 = tf.get_default_graph().get_tensor_by_name(\"FC2/w2:0\")\n",
    "    \n",
    "    x = tf.get_default_graph().get_tensor_by_name(\"place_holder/x:0\")\n",
    "    y = tf.get_default_graph().get_tensor_by_name(\"place_holder/y:0\")\n",
    "        \n",
    "    stk_CW1 = sess.run([tf.stack([CW1,CW1,CW1])],{x: np.random.rand(1,110,84,4),y: np.random.rand(1,4)})\n",
    "    stk_CW2 = sess.run([tf.stack([CW2,CW2,CW2])],{x: np.random.rand(1,110,84,4),y: np.random.rand(1,4)})\n",
    "    stk_FW1 = sess.run([tf.stack([FW1,FW1,FW1])],{x: np.random.rand(1,110,84,4),y: np.random.rand(1,4)})\n",
    "    stk_FW2 = sess.run([tf.stack([FW2,FW2,FW2])],{x: np.random.rand(1,110,84,4),y: np.random.rand(1,4)})\n",
    "    \n",
    "    \n",
    "    with tf.name_scope(\"constants\"):\n",
    "        tf.constant(np.squeeze(stk_CW1),name=\"C1w1_store\")\n",
    "        tf.constant(np.squeeze(stk_CW2),name=\"C2w2_store\")\n",
    "        tf.constant(np.squeeze(stk_FW1),name=\"FC1w1_store\")\n",
    "        tf.constant(np.squeeze(stk_FW2),name=\"FC2w2_store\")\n",
    "    return\n",
    "    \n",
    "        \n",
    "    \n",
    "def WB_tensors():\n",
    "    tvar = tf.trainable_variables()    \n",
    "    return tvar\n",
    "\n",
    "def loss_fun():\n",
    "    return\n",
    "\n",
    "def iteration(sess,input_imgs):\n",
    "    #0 Future, 1 Present, 2 Past\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,batch_size,conv_count,fc_count,conv_feats,fc_feats,conv_k_size,conv_stride):\n",
    "    LOGDIR = r\"C:\\Users\\Vishnu\\Documents\\EngProj\\SSPlayer\\log\"\n",
    "    if (len(conv_feats) != conv_count):\n",
    "        return\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"place_holder\"):\n",
    "        x = tf.placeholder(tf.float32,shape=[1,110,84,4],name=\"x\")\n",
    "        y = tf.placeholder(tf.float32,shape=[1,4],name=\"y\")\n",
    "            \n",
    "    convs = []\n",
    "    convs.append(x)\n",
    "    conv_name=\"conv\"\n",
    "    conv_feats[0] = 4\n",
    "    p = 0\n",
    "    for i in range(0,conv_count-1):\n",
    "        convs.append(conv_layer(convs[i],conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_k_size[p],conv_stride[p],2,2,conv_name,str(i+1)))\n",
    "    \n",
    "    \n",
    "    shape = (convs[conv_count-1]).get_shape().as_list()\n",
    "    fc_feats[0] = shape[1]*shape[2]*conv_feats[conv_count-1]\n",
    "    flatten = tf.reshape(convs[conv_count-1],[-1,fc_feats[0]])\n",
    "    \n",
    "    fcs = []\n",
    "    fcs.append(flatten)\n",
    "    fcs_name = \"FC\"\n",
    "    for i in range(0,fc_count-1):\n",
    "        fcs.append((fc_layer(fcs[i],fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))))\n",
    "    \n",
    "    logts = fcs[len(fcs)-1]\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    construct_weight_matricies()\n",
    "    #with tf.Session() as sess:\n",
    "    #    sess.run(tf.global_variables_initializer())\n",
    "    #    writer.add_graph(sess.graph)\n",
    "    #    writer.close()\n",
    "        \n",
    "    #return convs,fcs,[x,y],summ,writer\n",
    "    return sess,writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdevconv1:  0.08838834764831845\n",
      "sdevconv2:  0.04419417382415922\n",
      "sdevFC1:  0.0078125\n",
      "sdevFC2:  0.04419417382415922\n"
     ]
    }
   ],
   "source": [
    "conv_k_size = [8,4]\n",
    "conv_stride = [4,2]\n",
    "conv = [0,16,32]\n",
    "fclyr = [0,256,4]\n",
    "conv_count = len(conv)\n",
    "fc_count = len(fclyr)\n",
    "learning_rate = 1e-4\n",
    "batch_size = 10\n",
    "sess,writer = create_model(learning_rate,batch_size,conv_count,fc_count,conv,fclyr,conv_k_size,conv_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8, 8, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "construct_weight_matricies()\n",
    "writer.add_graph(sess.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
