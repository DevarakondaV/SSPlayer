{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(m_input,size_in,size_out,k_size_w,k_size_h,conv_stride,pool_k_size,pool_stride_size,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        dim = tf.get_default_graph().get_tensor_by_name(\"place_holder/dim:0\")\n",
    "        w = tf.get_default_graph().get_tensor_by_name(\"conv_weights/w\"+num+\":0\")[dim]\n",
    "        b = tf.get_default_graph().get_tensor_by_name(\"conv_weights/b\"+num+\":0\")[dim]\n",
    "        conv = tf.nn.conv2d(m_input,w,strides=[1,conv_stride,conv_stride,1],padding=\"SAME\")\n",
    "        act = tf.nn.leaky_relu((conv+b),alpha=0.3)\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return tf.nn.max_pool(act,ksize=[1,pool_k_size,pool_k_size,1],strides=[1,pool_stride_size,pool_stride_size,1],padding='SAME')\n",
    "\n",
    "\n",
    "def fc_layer(m_input,size_in,size_out,name,num):\n",
    "    with tf.name_scope(name+num):\n",
    "        dim = tf.get_default_graph().get_tensor_by_name(\"place_holder/dim:0\")\n",
    "        w = tf.get_default_graph().get_tensor_by_name(\"fc_weights/w\"+num+\":0\")[dim]\n",
    "        b = tf.get_default_graph().get_tensor_by_name(\"fc_weights/b\"+num+\":0\")[dim]\n",
    "        z = tf.matmul(m_input,w)\n",
    "        act = tf.nn.leaky_relu(z+b,alpha=0.3,name=(\"act\"+num))\n",
    "        tf.summary.histogram(\"act\",act)\n",
    "        return act\n",
    "    \n",
    "def conv_weights(size_in, size_out, k_size_w, k_size_h,name,num):\n",
    "    sdev = np.power(2.0/(k_size_w*k_size_h*size_in),0.5)\n",
    "    print(\"sdev\"+name+num+\": \",sdev)\n",
    "    wi = tf.Variable(tf.truncated_normal([k_size_w,k_size_h,size_in,size_out],stddev = sdev))#,name=(\"w\"+num))\n",
    "    bi = tf.Variable(tf.constant(.1,shape=[size_out]))#,name=(\"b\"+num))\n",
    "    w = tf.squeeze(tf.stack([wi,wi]),name=(\"w\"+num))\n",
    "    b = tf.squeeze(tf.stack([bi,bi]),name=(\"b\"+num))\n",
    "    tf.summary.histogram(\"weights\",wi)\n",
    "    tf.summary.histogram(\"biases\",bi)\n",
    "        \n",
    "def fc_weights(size_in,size_out,name,num):\n",
    "    sdev = np.power(2.0/(size_in*size_out),0.5)\n",
    "    print(\"sdev\"+name+num+\": \",sdev)\n",
    "    wi = tf.Variable(tf.truncated_normal([size_in,size_out],stddev = sdev))#,name=(\"w\"+num))\n",
    "    bi = tf.Variable(tf.constant(0.1,shape=[size_out]))#,name=(\"b\"+num))\n",
    "    w = tf.squeeze(tf.stack([wi,wi]),name=(\"w\"+num))\n",
    "    b = tf.squeeze(tf.stack([bi,bi]),name=(\"b\"+num))\n",
    "    tf.summary.histogram(\"weights\",wi)\n",
    "    tf.summary.histogram(\"biases\",bi)\n",
    "    \n",
    "    \n",
    "def get_place_holders():\n",
    "    a = tf.get_default_graph().get_tensor_by_name(\"place_holder/x1:0\")\n",
    "    b = tf.get_default_graph().get_tensor_by_name(\"place_holder/y:0\")\n",
    "    c = tf.get_default_graph().get_tensor_by_name(\"place_holder/x2:0\")\n",
    "    d = tf.get_default_graph().get_tensor_by_name(\"place_holder/next_state:0\")\n",
    "    e = tf.get_default_graph().get_tensor_by_name(\"place_holder/qnext:0\")\n",
    "    return a,b,c,d,e\n",
    "\n",
    "def get_WBS():\n",
    "    CW1 = tf.get_default_graph().get_tensor_by_name(\"conv_weights/w1:0\")\n",
    "    CW2 = tf.get_default_graph().get_tensor_by_name(\"conv_weights/w2:0\")\n",
    "    FW1 = tf.get_default_graph().get_tensor_by_name(\"fc_weights/w1:0\")\n",
    "    FW2 = tf.get_default_graph().get_tensor_by_name(\"fc_weights/w2:0\")\n",
    "\n",
    "    CB1 = tf.get_default_graph().get_tensor_by_name(\"conv_weights/b1:0\")\n",
    "    CB2 = tf.get_default_graph().get_tensor_by_name(\"conv_weights/b2:0\")\n",
    "    FB1 = tf.get_default_graph().get_tensor_by_name(\"fc_weights/b1:0\")\n",
    "    FB2 = tf.get_default_graph().get_tensor_by_name(\"fc_weights/b2:0\")\n",
    "    \n",
    "    return [CW1,CW2,FW1,FW2],[CB1,CB2,FB1,FB2]\n",
    "    \n",
    "def update_weight_params():\n",
    "    return\n",
    "    \n",
    "def trainer(sess,current_state,next_state,reward,gamma):\n",
    "    train = tf.get_default_graph().get_operation_by_name(\"train/trainer\")\n",
    "    x1,y,x2,next_state_bool,Qnext = get_place_holders()\n",
    "    output = tf.get_default_graph().get_tensor_by_name(\"FC2/act2/Maximum:0\")\n",
    "    dim = tf.get_default_graph().get_tensor_by_name(\"place_holder/dim:0\")\n",
    "    \n",
    "    w,b = get_WBS()\n",
    "    \n",
    "    print(\"current: \",sess.run([w[0][0][0][0][0][0]]))\n",
    "    print(\"previous: \",sess.run([w[0][1][0][0][0][0]]))\n",
    "    Qnext_val,d = sess.run([output,dim],{x1: current_state, x2: next_state,next_state_bool: True,dim: 0})\n",
    "    #print(\"Qvals: \",Qnext_val)\n",
    "    Qnext_val = reward+(gamma*np.max(Qnext_val))\n",
    "    Qnext_val = np.array(Qnext_val).reshape((1,1))\n",
    "    print(\"current: \",sess.run([w[0][0][0][0][0][0]]))\n",
    "    print(\"previous: \",sess.run([w[0][1][0][0][0][0]]))\n",
    "    #print(\"Max Q: \",Qnext_val)\n",
    "    print(\"dim: \",d)\n",
    "    s,d = sess.run([train,dim],{x1: current_state,x2: next_state, next_state_bool: False, Qnext: Qnext_val,dim: 1})\n",
    "    print(\"current: \",sess.run([w[0][0][0][0][0][0]]))\n",
    "    print(\"previous: \",sess.run([w[0][1][0][0][0][0]]))\n",
    "    #update_weight_params()\n",
    "    print(\"dim: \",d)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,batch_size,conv_count,fc_count,conv_feats,fc_feats,conv_k_size,conv_stride):\n",
    "    LOGDIR = r\"C:\\Users\\devar\\Documents\\EngProj\\SSPlayer\\log\"\n",
    "    if (len(conv_feats) != conv_count):\n",
    "        return\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.name_scope(\"place_holder\"):\n",
    "        x1 = tf.placeholder(tf.float32,shape=[1,110,84,4],name=\"x1\")\n",
    "        y = tf.placeholder(tf.float32,shape=[1,4],name=\"y\")\n",
    "        x2 = tf.placeholder(tf.float32,shape=[1,110,84,4],name=\"x2\")\n",
    "        next_state = tf.placeholder(tf.bool,name=\"next_state\")\n",
    "        Qnext = tf.placeholder(tf.float32,shape=[1,1],name=\"qnext\")\n",
    "        dim = tf.placeholder(tf.int32,name=\"dim\")\n",
    "        \n",
    "        \n",
    "    #with tf.name_scope(\"vars\"):\n",
    "        #0 is current params. 1 is previous\n",
    "    #    dim = tf.Variable(1,name=\"dim\")\n",
    "\n",
    "    conv_name=\"conv\"\n",
    "    conv_feats[0] = 4\n",
    "    p = 0\n",
    "    with tf.name_scope(\"conv_weights\"):\n",
    "        for i in range(0,conv_count-1):\n",
    "            conv_weights(conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_stride[p],conv_name,str(i+1))\n",
    "            p = p+1\n",
    "    \n",
    "    fcs_name=\"FC\"\n",
    "    fc_feats[0] = conv_feats[len(conv_feats)-1]*4\n",
    "    with tf.name_scope(\"fc_weights\"):\n",
    "        for i in range(0,fc_count-1):\n",
    "            fc_weights(fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "    \n",
    "    def f_true():\n",
    "        #assign_op = tf.assign(dim,1)\n",
    "        #tf.control_dependencies([assign_op])\n",
    "        return x2\n",
    "    \n",
    "    def f_false():\n",
    "        #assign_op = tf.assign(dim,0)\n",
    "        #tf.control_dependencies([assign_op])\n",
    "        return x1\n",
    "    \n",
    "    in_image = tf.cond(next_state,f_true,f_false,name=\"state_condition\")\n",
    "            \n",
    "\n",
    "    convs = []\n",
    "    convs.append(in_image)    \n",
    "    p = 0\n",
    "    for i in range(0,conv_count-1):\n",
    "        convs.append(conv_layer(convs[i],conv_feats[i],conv_feats[i+1],conv_k_size[p],conv_k_size[p],conv_stride[p],2,2,conv_name,str(i+1)))\n",
    "    \n",
    "\n",
    "    flatten = tf.reshape(convs[conv_count-1],[-1,fc_feats[0]])\n",
    "    \n",
    "    fcs = []\n",
    "    fcs.append(flatten)\n",
    "    for i in range(0,fc_count-1):\n",
    "        fcs.append((fc_layer(fcs[i],fc_feats[i],fc_feats[i+1],fcs_name,str(i+1))))\n",
    "    \n",
    "    output_layer = fcs[len(fcs)-1]\n",
    "    \n",
    "    \n",
    "    #sess = tf.InteractiveSession()\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        loss = tf.reduce_sum(Qnext-output_layer)\n",
    "        train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,name=\"trainer\")\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    return sess,writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdevconv1:  0.125\n",
      "sdevconv2:  0.125\n",
      "sdevFC1:  0.0078125\n",
      "sdevFC2:  0.04419417382415922\n"
     ]
    }
   ],
   "source": [
    "conv_k_size = [8,4]\n",
    "conv_stride = [4,2]\n",
    "conv = [0,16,32]\n",
    "fclyr = [0,256,4]\n",
    "conv_count = len(conv)\n",
    "fc_count = len(fclyr)\n",
    "learning_rate = 1e-4\n",
    "batch_size = 10\n",
    "sess,writer = create_model(learning_rate,batch_size,conv_count,fc_count,conv,fclyr,conv_k_size,conv_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer.add_graph(sess.graph)\n",
    "#assign_weights_to_model(0,sess)\n",
    "#loss_fun(np.random.rand(1,110,84,4),np.random.rand(1,110,84,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current:  [0.056483813]\n",
      "previous:  [0.056483813]\n",
      "current:  [0.056483813]\n",
      "previous:  [0.056483813]\n",
      "dim:  0\n",
      "current:  [0.056482583]\n",
      "previous:  [0.056482583]\n",
      "dim:  1\n"
     ]
    }
   ],
   "source": [
    "trainer(sess,np.random.rand(1,110,84,4),np.random.rand(1,110,84,4),5,.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
